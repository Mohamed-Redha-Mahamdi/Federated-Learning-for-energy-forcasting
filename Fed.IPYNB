{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flwr as fl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from flwr.client import NumPyClient, Client\n",
    "from flwr.common import Context\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import torch.multiprocessing as mp\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flwr as fl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from flwr.client import NumPyClient, Client\n",
    "from flwr.common import Context\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import torch.multiprocessing as mp\n",
    "import warnings\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*flwr.simulation.start_simulation.*\")\n",
    "\n",
    "# Set multiprocessing start method to 'spawn' for compatibility\n",
    "try:\n",
    "    mp.set_start_method('spawn')\n",
    "except RuntimeError:\n",
    "    pass\n",
    "\n",
    "# Set up logging for detailed training information\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Function to load and prepare data\n",
    "def get_dataloader(file_name: str, batch_size: int = 128, num_workers: int = 8) -> DataLoader:\n",
    "    \"\"\"Loads data from a CSV file and returns a DataLoader.\"\"\"\n",
    "    required_columns = ['Vehicle Speed[km/h]', 'Acceleration_ms2', 'OAT[DegC]', 'Slope_deg', 'Energy_Consumption']\n",
    "    df = pd.read_csv(file_name, low_memory=False)\n",
    "    df = df[[col for col in required_columns if col in df.columns]]\n",
    "    \n",
    "    # Check for NaN or infinite values (optional, since you confirmed no missing data)\n",
    "    if df.isnull().values.any():\n",
    "        logger.warning(f\"NaN values found in {file_name}\")\n",
    "    if np.isinf(df.values).any():\n",
    "        logger.warning(f\"Infinite values found in {file_name}\")\n",
    "    \n",
    "    X = df[['Vehicle Speed[km/h]', 'Acceleration_ms2', 'OAT[DegC]', 'Slope_deg']].values.astype(np.float32)\n",
    "    y = df['Energy_Consumption'].values.astype(np.float32).reshape(-1, 1)\n",
    "    \n",
    "    # Additional checks for tensor integrity\n",
    "    if torch.isnan(torch.tensor(X)).any() or torch.isinf(torch.tensor(X)).any():\n",
    "        logger.warning(f\"NaN or Inf values in features of {file_name}\")\n",
    "    if torch.isnan(torch.tensor(y)).any() or torch.isinf(torch.tensor(y)).any():\n",
    "        logger.warning(f\"NaN or Inf values in targets of {file_name}\")\n",
    "    \n",
    "    dataset = TensorDataset(torch.tensor(X), torch.tensor(y))\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "class ComplexNet(nn.Module):\n",
    "    \"\"\"A complex neural network with batch normalization and dropout.\"\"\"\n",
    "    def __init__(self, input_dim: int = 4):\n",
    "        super(ComplexNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.fc2 = nn.Linear(64, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.bn4 = nn.BatchNorm1d(32)\n",
    "        self.fc5 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the FedProx client\n",
    "class FedProxNumPyClient(NumPyClient):\n",
    "    \"\"\"A FedProx client implementation with NumPy interface.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        cid: str,\n",
    "        model: nn.Module,\n",
    "        dataloader: DataLoader,\n",
    "        device: torch.device,\n",
    "        local_epochs: int = 10,\n",
    "        lr: float = 0.001,\n",
    "        mu: float = 0.01,\n",
    "    ):\n",
    "        self.cid = cid\n",
    "        self.model = model\n",
    "        self.dataloader = dataloader\n",
    "        self.local_epochs = local_epochs\n",
    "        self.lr = lr\n",
    "        self.mu = mu\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.device = device\n",
    "        self.model.to(self.device)\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=self.lr)\n",
    "        self.global_model = ComplexNet().to(self.device)\n",
    "        self.global_model.load_state_dict(self.model.state_dict())\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        \"\"\"Return model parameters as NumPy arrays.\"\"\"\n",
    "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        \"\"\"Set model parameters from NumPy arrays.\"\"\"\n",
    "        state_dict = self.model.state_dict()\n",
    "        new_state_dict = {}\n",
    "        for k, arr in zip(state_dict.keys(), parameters):\n",
    "            new_state_dict[k] = torch.tensor(arr, device=self.device)\n",
    "        self.model.load_state_dict(new_state_dict)\n",
    "        self.global_model.load_state_dict(new_state_dict)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        \"\"\"Train the model locally with FedProx regularization.\"\"\"\n",
    "        self.set_parameters(parameters)\n",
    "        self.model.train()\n",
    "        server_round = config.get(\"server_round\", 1)\n",
    "        logger.info(f\"Client {self.cid} - Starting training for Round {server_round}\")\n",
    "        \n",
    "        with tqdm(total=self.local_epochs, desc=f\"Client {self.cid} - Round {server_round}\", unit=\"epoch\") as pbar:\n",
    "            for epoch in range(self.local_epochs):\n",
    "                epoch_loss = 0.0\n",
    "                epoch_prox = 0.0\n",
    "                for X, y in self.dataloader:\n",
    "                    X, y = X.to(self.device), y.to(self.device)\n",
    "                    self.optimizer.zero_grad()\n",
    "                    output = self.model(X)\n",
    "                    loss = self.criterion(output, y)\n",
    "                    prox_term = 0.0\n",
    "                    for param, global_param in zip(self.model.parameters(), self.global_model.parameters()):\n",
    "                        prox_term += torch.norm(param - global_param) ** 2\n",
    "                    total_loss = loss + (self.mu / 2) * prox_term\n",
    "                    total_loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "                    self.optimizer.step()\n",
    "                    epoch_loss += loss.item() * X.size(0)\n",
    "                    epoch_prox += prox_term.item() * X.size(0)\n",
    "                avg_loss = epoch_loss / len(self.dataloader.dataset)\n",
    "                avg_prox = epoch_prox / len(self.dataloader.dataset)\n",
    "                logger.info(f\"Client {self.cid} - Round {server_round} - Epoch {epoch + 1}/{self.local_epochs} - Avg Loss: {avg_loss:.4f}, Avg Prox Term: {avg_prox:.4f}\")\n",
    "                pbar.update(1)\n",
    "        return self.get_parameters({}), len(self.dataloader.dataset), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        \"\"\"Evaluate the model and compute loss and MAE.\"\"\"\n",
    "        self.set_parameters(parameters)\n",
    "        self.model.eval()\n",
    "        loss_total = 0.0\n",
    "        mae_total = 0.0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for X, y in self.dataloader:\n",
    "                X, y = X.to(self.device), y.to(self.device)\n",
    "                output = self.model(X)\n",
    "                loss = self.criterion(output, y)\n",
    "                mae = torch.mean(torch.abs(output - y))\n",
    "                batch_size = X.size(0)\n",
    "                loss_total += loss.item() * batch_size\n",
    "                mae_total += mae.item() * batch_size\n",
    "                total += batch_size\n",
    "        avg_loss = loss_total / total\n",
    "        avg_mae = mae_total / total\n",
    "        logger.info(f\"Client {self.cid} - Evaluation Loss: {avg_loss:.4f}, MAE: {avg_mae:.4f}\")\n",
    "        return avg_loss, total, {\"mae\": avg_mae}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the client function for Flower\n",
    "def client_fn(context: Context) -> Client:\n",
    "    \"\"\"Create a client instance based on the context.\"\"\"\n",
    "    cid = context.node_id\n",
    "    file_names = [\"vehicle_4.csv\", \"vehicle_455_data.csv\", \"vehicle_10_data.csv\", \"vehicle_541_data.csv\"]\n",
    "    file_name = file_names[int(cid)]\n",
    "    dataloader = get_dataloader(file_name, batch_size=32, num_workers=4)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = ComplexNet()\n",
    "    numpy_client = FedProxNumPyClient(\n",
    "        cid=cid,\n",
    "        model=model,\n",
    "        dataloader=dataloader,\n",
    "        device=device,\n",
    "        local_epochs=10,\n",
    "        lr=0.001,  # Adjusted learning rate\n",
    "        mu=0.01,   # FedProx mu parameter\n",
    "    )\n",
    "    return numpy_client.to_client()\n",
    "\n",
    "# Custom FedAvg strategy\n",
    "class CustomFedAvg(fl.server.strategy.FedAvg):\n",
    "    \"\"\"Custom FedAvg strategy with enhanced logging.\"\"\"\n",
    "    def __init__(self, *args, num_rounds=10, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.num_rounds = num_rounds\n",
    "        self.round_losses = []\n",
    "\n",
    "    def configure_fit(self, server_round, parameters, client_manager):\n",
    "        \"\"\"Configure the fit process with server round information.\"\"\"\n",
    "        client_instructions = super().configure_fit(server_round, parameters, client_manager)\n",
    "        config = {\"server_round\": server_round}\n",
    "        updated_instructions = [\n",
    "            (client_proxy, fl.common.FitIns(fit_ins.parameters, config))\n",
    "            for client_proxy, fit_ins in client_instructions\n",
    "        ]\n",
    "        return updated_instructions\n",
    "\n",
    "    def fit(self, server_round, parameters, config):\n",
    "        \"\"\"Run the fit process for a server round.\"\"\"\n",
    "        logger.info(f\"Starting Server Round {server_round}/{self.num_rounds}\")\n",
    "        with tqdm(total=1, desc=f\"Server Round {server_round}/{self.num_rounds}\", unit=\"round\") as pbar:\n",
    "            res = super().fit(server_round, parameters, config)\n",
    "            pbar.update(1)\n",
    "        return res\n",
    "\n",
    "    def evaluate(self, server_round, parameters):\n",
    "        \"\"\"Evaluate the model and store the loss.\"\"\"\n",
    "        res = super().evaluate(server_round, parameters)\n",
    "        if res is not None:\n",
    "            loss, metrics = res\n",
    "            self.round_losses.append((server_round, loss))\n",
    "            logger.info(f\"Server - Round {server_round} - Evaluation Loss: {loss:.4f}\")\n",
    "        return res\n",
    "\n",
    "    def finalize(self):\n",
    "        \"\"\"Display final metrics after simulation.\"\"\"\n",
    "        logger.info(\"\\n=== Final Metrics ===\")\n",
    "        for round_num, loss in self.round_losses:\n",
    "            logger.info(f\"Round {round_num} - Distributed Loss: {loss:.4f}\")\n",
    "        if self.round_losses:\n",
    "            avg_loss = sum(loss for _, loss in self.round_losses) / len(self.round_losses)\n",
    "            logger.info(f\"Average Distributed Loss Across All Rounds: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting Federated Learning Simulation\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Unable to import module `ray`.\n\nTo install the necessary dependencies, install `flwr` with the `simulation` extra:\n\n    pip install -U \"flwr[simulation]\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Start the simulation with GPU resources\u001b[39;00m\n\u001b[32m     14\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mStarting Federated Learning Simulation\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m hist = \u001b[43mfl\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimulation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_clients\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mserver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mServerConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_resources\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnum_cpus\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnum_gpus\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Leverage your GPUs\u001b[39;49;00m\n\u001b[32m     21\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Check simulation result\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hist \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mredh\\Documents\\Projet FEVC\\venv\\Lib\\site-packages\\flwr\\simulation\\__init__.py:38\u001b[39m, in \u001b[36mstart_simulation\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstart_simulation\u001b[39m(*args, **kwargs):  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Log error stating that module `ray` could not be imported.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(RAY_IMPORT_ERROR)\n",
      "\u001b[31mImportError\u001b[39m: Unable to import module `ray`.\n\nTo install the necessary dependencies, install `flwr` with the `simulation` extra:\n\n    pip install -U \"flwr[simulation]\"\n"
     ]
    }
   ],
   "source": [
    "# Main execution block\n",
    "if __name__ == \"__main__\":\n",
    "    num_rounds = 10\n",
    "    strategy = CustomFedAvg(\n",
    "        fraction_fit=1.0,\n",
    "        fraction_evaluate=1.0,\n",
    "        min_fit_clients=4,\n",
    "        min_evaluate_clients=4,\n",
    "        min_available_clients=4,\n",
    "        num_rounds=num_rounds,\n",
    "    )\n",
    "\n",
    "    # Start the simulation with GPU resources\n",
    "    logger.info(\"Starting Federated Learning Simulation\")\n",
    "    hist = fl.simulation.start_simulation(\n",
    "        client_fn=client_fn,\n",
    "        num_clients=4,\n",
    "        config=fl.server.ServerConfig(num_rounds=num_rounds),\n",
    "        strategy=strategy,\n",
    "        client_resources={\"num_cpus\": 1, \"num_gpus\": 1},  # Leverage your GPUs\n",
    "    )\n",
    "\n",
    "    # Check simulation result\n",
    "    if hist is not None:\n",
    "        logger.info(\"Simulation completed successfully.\")\n",
    "    else:\n",
    "        logger.error(\"Simulation failed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
